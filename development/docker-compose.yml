services:
  go-server:
    build:
      context: ../server
      dockerfile: Dockerfile
    container_name: main-server
    hostname: main-server
    env_file:
      - .env
    ports:
      - 4000:4000
    depends_on:
      postgresdb:
        condition: service_healthy
      redis:
        condition: service_healthy
    deploy:
      restart_policy:
        condition: on-failure
    restart: on-failure
    volumes:
      - ../server:/app
      - ./docker/.aws:/$HOME/.aws:ro # for aws credentials
    networks:
      - default

  postgresdb:
    image: arm64v8/postgres:17-trixie
    container_name: postgres_db
    hostname: postgres_db
    expose:
      - 5432
    env_file:
      - .env
    ports:
      - 5432:5432
    restart: on-failure
    volumes:
      - ./docker/pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d ${POSTGRES_DB} -U ${POSTGRES_USER}"]
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 20s
    networks:
      - default

  redis:
    container_name: "redis"
    hostname: redis
    image: arm64v8/redis #redis:alpine
    env_file:
      - .env
    # Specify the redis.conf file to use and add a password.
    command: redis-server /usr/local/etc/redis/redis.conf --requirepass ${REDIS_PASSWORD}
    ports:
      - ${REDIS_PORT}:${REDIS_PORT}
    expose:
      - ${REDIS_PORT}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5
    volumes:
      - ./docker/data/:/data
      - ./docker/redis/redis.conf:/usr/local/etc/redis/redis.conf
    networks:
      - default

  zitadel:
    restart: unless-stopped
    image: ghcr.io/zitadel/zitadel:latest
    command: start-from-init --masterkey "MasterkeyNeedsToHave32Characters"
    env_file:
      - .env
    environment:
      # See "What's next" to learn about how to serve Zitadel on a different domain or IP.
      ZITADEL_EXTERNALDOMAIN: localhost

      # See "What's next" to learn about how to enable TLS.
      ZITADEL_EXTERNALSECURE: false
      ZITADEL_TLS_ENABLED: false

      # Database connection settings.
      ZITADEL_DATABASE_POSTGRES_HOST: postgresdb
      ZITADEL_DATABASE_POSTGRES_PORT: 5432
      # The database is created by the init job if it does not exist.
      ZITADEL_DATABASE_POSTGRES_DATABASE: zitadel
      # The admin user must already exist in the database.
      ZITADEL_DATABASE_POSTGRES_ADMIN_USERNAME: ${POSTGRES_USER}
      ZITADEL_DATABASE_POSTGRES_ADMIN_PASSWORD: ${POSTGRES_PASSWORD}
      ZITADEL_DATABASE_POSTGRES_ADMIN_SSL_MODE: disable
      # The zitadel user is created by the init job if it does not exist.
      ZITADEL_DATABASE_POSTGRES_USER_USERNAME: zitadel
      ZITADEL_DATABASE_POSTGRES_USER_PASSWORD: zitadel
      ZITADEL_DATABASE_POSTGRES_USER_SSL_MODE: disable
      
      # By configuring a login client, the setup job creates a user of type machine with the role IAM_LOGIN_CLIENT.
      # It writes a PAT to the path specified in ZITADEL_FIRSTINSTANCE_LOGINCLIENTPATPATH.
      # The PAT is passed to the login container via the environment variable ZITADEL_SERVICE_USER_TOKEN_FILE.
      ZITADEL_FIRSTINSTANCE_LOGINCLIENTPATPATH: /current-dir/login-client.pat
      ZITADEL_FIRSTINSTANCE_ORG_HUMAN_PASSWORDCHANGEREQUIRED: false
      ZITADEL_FIRSTINSTANCE_ORG_LOGINCLIENT_MACHINE_USERNAME: login-client
      ZITADEL_FIRSTINSTANCE_ORG_LOGINCLIENT_MACHINE_NAME: Automatically Initialized IAM_LOGIN_CLIENT
      ZITADEL_FIRSTINSTANCE_ORG_LOGINCLIENT_PAT_EXPIRATIONDATE: '2029-01-01T00:00:00Z'
      # Activate the login v2 on an installation from scratch.
      # To activate the login v2 on an existing installation, read the "What's next" section.
      ZITADEL_DEFAULTINSTANCE_FEATURES_LOGINV2_REQUIRED: true # To use the login v1, set this to false.
      ZITADEL_DEFAULTINSTANCE_FEATURES_LOGINV2_BASEURI: http://localhost:3000/ui/v2/login
      # Configure the redirection paths to the login v2.
      ZITADEL_OIDC_DEFAULTLOGINURLV2: http://localhost:3000/ui/v2/login/login?authRequest=
      ZITADEL_OIDC_DEFAULTLOGOUTURLV2: http://localhost:3000/ui/v2/login/logout?post_logout_redirect=
      ZITADEL_SAML_DEFAULTLOGINURLV2: http://localhost:3000/ui/v2/login/login?samlRequest=

      # By configuring a machine, the setup job creates a user of type machine with the role IAM_OWNER.
      # It writes a personal access token (PAT) to the path specified in ZITADEL_FIRSTINSTANCE_PATPATH.
      # The PAT can be used to provision resources with [Terraform](/docs/guides/manage/terraform-provider), for example.
      # ZITADEL_FIRSTINSTANCE_PATPATH: /current-dir/admin.pat
      # ZITADEL_FIRSTINSTANCE_ORG_MACHINE_MACHINE_USERNAME: admin
      # ZITADEL_FIRSTINSTANCE_ORG_MACHINE_MACHINE_NAME: Automatically Initialized IAM_OWNER
      # ZITADEL_FIRSTINSTANCE_ORG_MACHINE_PAT_EXPIRATIONDATE: '2029-01-01T00:00:00Z'
      
      # To change the initial human admin users username and password, uncomment the following lines.
      # The first login name is formatted like this: <username>@<org_name>.<external_domain>
      # With the following incommented configuration, this would be root@my-organization.localhost
      # Visit http://localhost:8080/ui/console to check if the login name works.
      # If you can't log in, check the available login names:
      # echo "select * from projections.login_names3;" | psql -h localhost -U postgres -d zitadel
      # The postgres users password is postgres.
      # ZITADEL_FIRSTINSTANCE_ORG_NAME: My Organization
      # ZITADEL_FIRSTINSTANCE_ORG_HUMAN_USERNAME: root
      # ZITADEL_FIRSTINSTANCE_ORG_HUMAN_PASSWORD: RootPassword1!

      # Enable debug logs
      # ZITADEL_LOG_LEVEL: debug     
      # Write Access Logs to stdout.
      # ZITADEL_LOGSTORE_ACCESS_STDOUT_ENABLED: true
    healthcheck:
      test:
        - CMD
        - /app/zitadel
        - ready
      interval: 10s
      timeout: 60s
      retries: 5
      start_period: 10s
    volumes:
      - .:/current-dir:delegated
    ports:
      - 8080:8080
      - 3000:3000
    networks:
      - default
    depends_on:
      postgresdb:
        condition: service_healthy

  login:
    restart: unless-stopped
    image: ghcr.io/zitadel/zitadel-login:latest
    # If you can't use the network_mode service:zitadel, you can pass the environment variables ZITADEL_API_URL=http://zitadel:8080 and CUSTOM_REQUEST_HEADERS=Host:localhost instead.
    environment:
      - ZITADEL_API_URL=http://localhost:8080
      - NEXT_PUBLIC_BASE_PATH=/ui/v2/login
      - ZITADEL_SERVICE_USER_TOKEN_FILE=/current-dir/login-client.pat
    network_mode: service:zitadel
    user: "0"
    volumes:
      - .:/current-dir:ro
    depends_on:
      zitadel:
        condition: service_healthy
        restart: false

  # chromedp:
  #   build:
  #     context: ../server
  #     dockerfile: Dockerfile.scrapper
  #   ports:
  #     - 9222:9222
  #   container_name: chromedp
  #   hostname: chromedp
  #   volumes:
  #     - ../server:/app
  #     - $HOME/.aws/credentials:/root/.aws/credentials:ro #
  #   networks:
  #     - default
  #   extra_hosts:
  #     - "host.docker.internal:host-gateway"
  #   shm_size: 4g
# go-jobs:
  #   build:
  #     context: ./server
  #     dockerfile: Dockerfile.jobs
  #   container_name: housespot-jobs
  #   hostname: housespot-jobs
  #   env_file:
  #     - .env
  #   ports:
  #     - 4000:4000
  #   depends_on:
  #     postgresdb:
  #       condition: service_healthy
  #     redis:
  #       condition: service_healthy
  #   deploy:
  #     restart_policy:
  #       condition: on-failure
  #   restart: on-failure
  #   volumes:
  #     - ./server:/app
  #     - $HOME/.aws/credentials:/root/.aws/credentials:ro # for aws credentials
  #   networks:
  #     - default

  # asynqmon:
  #   image: hibiken/asynqmon:latest
  #   ports:
  #     - 8080:8080
  #   #entrypoint: ["./asynqmon", "--redis-addr=redis:6379"]
  #   entrypoint:
  #     [
  #       "./asynqmon",
  #       "--redis-url=redis://:${REDIS_PASSWORD}@${REDIS_HOST}:${REDIS_PORT}",
  #     ]
  #   depends_on:
  #     redis:
  #       condition: service_healthy
  #     #go-jobs:
  #     #   condition: service_started
  #   networks:
  #     - default

  # go-server.db.migrations:
  #   depends_on:
  #     postgresdb:
  #       condition: service_healthy
  #   image: go-server.db.migrations
  #   build:
  #     context: ./server/db/
  #     dockerfile: Dockerfile
  #   env_file:
  #     - .env
  #   restart: on-failure
  #   command: "postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}?sslmode=disable up"

volumes:
  pg_data:
    driver: local

networks:
  default:
